{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version 2.0.1\n",
      "PyG version 2.3.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import ortho_group\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, ReLU, BatchNorm1d, Module, Sequential\n",
    "from torch import Tensor\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "from torch_geometric.typing import (\n",
    "    Adj,\n",
    "    OptPairTensor,\n",
    "    OptTensor,\n",
    "    Size,\n",
    "    SparseTensor,\n",
    "    torch_sparse,\n",
    ")\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import Batch\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import remove_self_loops, to_dense_adj, dense_to_sparse, to_undirected\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MessagePassing, global_mean_pool, knn_graph\n",
    "from torch_geometric.datasets import QM9\n",
    "from torch_scatter import scatter\n",
    "from torch_cluster import knn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import uproot\n",
    "import vector\n",
    "vector.register_awkward()\n",
    "import awkward as ak\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "print(\"PyTorch version {}\".format(torch.__version__))\n",
    "print(\"PyG version {}\".format(torch_geometric.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's make the graph dataset from pointcloud dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta, phi = torch.randn([5, 1]), torch.randn([5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = torch.cat([eta, phi], dim=-1)\n",
    "pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch_geometric.nn.knn_graph(x = pos, k = 2)\n",
    "edge_index = to_undirected(edge_index, num_nodes=pos.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 4, 4],\n",
       "        [1, 4, 0, 4, 3, 4, 2, 4, 0, 1, 2, 3]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's create a jet-graph dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Jet_Dataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, dataset_path:str, tree_name:str = 'tree', k:int = 5) -> None:\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            size - Number of data points we want to generate\n",
    "            std - Standard deviation of the noise (see generate_continuous_xor function)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        self.dataset = uproot.open(dataset_path)\n",
    "        self.tree = self.dataset[tree_name].arrays()\n",
    "        \n",
    "        self.num_entries = self.dataset[tree_name].num_entries\n",
    "        \n",
    "        self.part_feat = self.dataset[tree_name].keys(filter_name='part_*')\n",
    "        self.jet_feat = self.dataset[tree_name].keys(filter_name='jet_*')\n",
    "        self.labels = self.dataset[tree_name].keys(filter_name='labels_*')\n",
    "        \n",
    "        self.k = k\n",
    "        \n",
    "        \n",
    "        #self.pc_dataset = [ self.transform_jet_to_point_cloud(idx) for idx in range(self.num_entries-1) ]\n",
    "        \n",
    "\n",
    "    def transform_jet_to_point_cloud(self, idx:int) -> Data :\n",
    "    \n",
    "        npart = self.tree['jet_nparticles'].to_numpy()[idx:idx+1]\n",
    "        \n",
    "        part_feat_list = [ak.flatten(self.tree[part_feat][idx:idx+1]).to_numpy() for part_feat in self.part_feat]\n",
    "        \n",
    "        jet_pt = self.tree['jet_pt'].to_numpy()[idx:idx+1]\n",
    "        jet_eta = self.tree['jet_eta'].to_numpy()[idx:idx+1]\n",
    "        jet_phi = self.tree['jet_phi'].to_numpy()[idx:idx+1]\n",
    "        jet_energy = self.tree['jet_energy'].to_numpy()[idx:idx+1]\n",
    "        jet_tau21 = self.tree['jet_tau2'].to_numpy()[idx:idx+1]/self.tree['jet_tau1'].to_numpy()[idx:idx+1]\n",
    "        jet_tau32 = self.tree['jet_tau3'].to_numpy()[idx:idx+1]/self.tree['jet_tau2'].to_numpy()[idx:idx+1]\n",
    "        jet_tau43 = self.tree['jet_tau4'].to_numpy()[idx:idx+1]/self.tree['jet_tau3'].to_numpy()[idx:idx+1]\n",
    "        \n",
    "        \n",
    "        jet_sd_mass = self.tree['jet_sdmass'].to_numpy()[idx:idx+1]\n",
    "        \n",
    "        jet_feat = np.stack([jet_pt, jet_eta, jet_phi, jet_energy, jet_tau21, jet_tau32, jet_tau43]).T\n",
    "              \n",
    "        jet_feat = np.repeat(jet_feat, int(npart), axis=0)\n",
    "             \n",
    "        part_feat = np.stack(part_feat_list).T\n",
    "        \n",
    "        total_jet_feat = np.concatenate((part_feat, jet_feat), axis=-1)\n",
    "        total_jet_feat[np.isnan(total_jet_feat)] = 0.\n",
    "        \n",
    "        #print(type(total_jet_feat), 'total_jet_feat shape : ', total_jet_feat.shape)\n",
    "        \n",
    "        jet_class = -1\n",
    "        \n",
    "        if(self.tree['label_QCD'].to_numpy()[idx:idx+1] == 1) : jet_class = 0\n",
    "        \n",
    "        if( (self.tree['label_Tbqq'].to_numpy()[idx:idx+1] == 1) or\n",
    "            (self.tree['label_Tbl'].to_numpy()[idx:idx+1] == 1)) : jet_class = 2\n",
    "        \n",
    "        if( (self.tree['label_Zqq'].to_numpy()[idx:idx+1] == 1) or\n",
    "            (self.tree['label_Wqq'].to_numpy()[idx:idx+1] == 1)) : jet_class = 0\n",
    "        \n",
    "        if( (self.tree['label_Hbb'].to_numpy()[idx:idx+1] == True) or\n",
    "            (self.tree['label_Hcc'].to_numpy()[idx:idx+1] == True) or\n",
    "            (self.tree['label_Hgg'].to_numpy()[idx:idx+1] == True) or\n",
    "            (self.tree['label_H4q'].to_numpy()[idx:idx+1] == True) or\n",
    "            (self.tree['label_Hqql'].to_numpy()[idx:idx+1] == True) ) : jet_class = 1\n",
    "        \n",
    "        part_eta = torch.tensor( ak.flatten(self.tree['part_deta'][idx:idx+1]).to_numpy() )\n",
    "        part_phi = torch.tensor( ak.flatten(self.tree['part_dphi'][idx:idx+1]).to_numpy() )\n",
    "        eta_phi_pos = torch.stack([part_eta, part_phi], dim=-1)\n",
    "        \n",
    "        edge_index = torch_geometric.nn.pool.knn_graph(x = eta_phi_pos, k = self.k)\n",
    "        \n",
    "        src, dst = edge_index\n",
    "                \n",
    "        part_del_eta = part_eta[dst] - part_eta[src]\n",
    "        part_del_phi = part_phi[dst] - part_phi[src]\n",
    "        \n",
    "        part_del_R = torch.hypot(part_del_eta, part_del_phi).view(-1, 1) # -- why do we need this view function ? \n",
    "        \n",
    "        data = Data(x=torch.tensor(total_jet_feat), edge_index=edge_index, edge_deltaR = part_del_R)\n",
    "        data.label = torch.tensor([jet_class])\n",
    "        data.sd_mass = torch.tensor(jet_sd_mass)\n",
    "        data.seq_length = torch.tensor(npart)\n",
    "        \n",
    "        return data    \n",
    "        \n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        # Number of data point we have. Alternatively self.data.shape[0], or self.label.shape[0]\n",
    "        return self.num_entries#len(self.pc_dataset)\n",
    "    \n",
    "    def __getitem__(self, idx:int) -> Data :\n",
    "        # Return the idx-th data point of the dataset\n",
    "    \n",
    "        return self.transform_jet_to_point_cloud(idx)#self.pc_dataset[idx]#data_point, data_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/Users/sanmay/Documents/ICTS_SCHOOL/Main_School/JetDataset/'\n",
    "file_name = dataset_path + 'JetClass_example_100k.root' # -- from -- \"https://hqu.web.cern.ch/datasets/JetClass/example/\" #\n",
    "jet_dataset = Jet_Dataset(dataset_path=file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset=jet_dataset, batch_size=1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9, 24,  1,  5,  2, 24, 38,  9,  0,  5,  5, 27, 33, 35, 22,  8, 40, 23,\n",
       "         16, 26, 11,  7, 17, 36, 25,  2, 35, 33, 27,  0, 20, 23, 10, 40, 16,  4,\n",
       "         30, 11, 17, 36,  3, 40, 28, 16, 26,  0, 24,  1,  5, 38, 23,  6, 16, 26,\n",
       "         20,  4, 17, 25, 36,  7, 36, 17, 25, 37, 11, 11, 25,  4, 17,  7, 37, 12,\n",
       "         36, 17, 25, 26, 34, 16, 18, 29, 26, 10, 23, 15, 20, 36, 11, 25,  4, 12,\n",
       "         29, 27, 15,  2,  5, 35, 33, 22,  5,  1,  6, 23, 40, 10, 16, 22, 33, 27,\n",
       "          2, 35, 33, 21, 35,  2,  5, 20, 10,  6, 16, 40,  9,  1,  0, 38,  5, 17,\n",
       "         11, 36,  4, 13, 16, 10, 15, 23, 20,  2,  5, 33, 22, 29,  8,  3, 32, 40,\n",
       "         16, 18, 27,  2,  5,  0,  7,  4, 11, 17, 13, 19, 38, 35,  1, 22, 40,  3,\n",
       "         20,  8, 23, 22, 35,  2,  5, 27, 21, 15, 22, 27, 33,  5, 33, 19, 22,  2,\n",
       "         17, 11, 12,  4, 25, 14, 12, 36, 17, 25,  1, 24,  9,  0, 19, 30, 28,  7,\n",
       "         13,  4, 23, 20,  3,  8,  6, 13, 39, 25, 11,  4],\n",
       "        [ 0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  3,  3,  3,\n",
       "          3,  3,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  7,\n",
       "          7,  7,  7,  7,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9, 10, 10, 10, 10,\n",
       "         10, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 14, 14,\n",
       "         14, 14, 14, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17,\n",
       "         18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 21, 21, 21,\n",
       "         21, 21, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 24, 24, 24, 24, 24, 25,\n",
       "         25, 25, 25, 25, 26, 26, 26, 26, 26, 27, 27, 27, 27, 27, 28, 28, 28, 28,\n",
       "         28, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 32, 32,\n",
       "         32, 32, 32, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 35, 35, 35, 35, 35,\n",
       "         36, 36, 36, 36, 36, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 39, 39, 39,\n",
       "         39, 39, 40, 40, 40, 40, 40, 41, 41, 41, 41, 41]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bg.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 42])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bg.ptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(bg.batch == 2)[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The flavors of message passing layer\n",
    "As a gentle introduction to PyTorch Geometric, we will introduce the first steps of developing a GNN in the **Message Passing** flavor.\n",
    "\n",
    "<!-- ![](https://drive.google.com/uc?id=1Wdgdq606XW1MelvcU1nW5CxWe1rHsWt1) -->\n",
    "<img src=\"https://github.com/chaitjo/dump/raw/main/gnn-layers.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Graph Convolution??\n",
    "\n",
    "$$H^{(l+1)} = \\sigma\\left(\\hat{D}^{-1/2}\\hat{A}\\hat{D}^{-1/2}H^{(l)}W^{(l)}\\right)$$\n",
    "\n",
    "$W^{(l)}$ is the weight parameters with which we transform the input features into messages ($H^{(l)}W^{(l)}$). To the adjacency matrix $A$ we add the identity matrix so that each node sends its own message also to itself: $\\hat{A}=A+I$. Finally, to take the average instead of summing, we calculate the matrix $\\hat{D}$ which is a diagonal matrix with $D_{ii}$ denoting the number of neighbors node $i$ has. $\\sigma$ represents an arbitrary activation function, and not necessarily the sigmoid (usually a ReLU-based activation function is used in GNNs). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GCN in traditional PyTorch way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, c_in, c_out):\n",
    "        super().__init__()\n",
    "        self.projection = nn.Linear(c_in, c_out)\n",
    "\n",
    "    def forward(self, x : Tensor, edge_index : Adj):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            node_feats - Tensor with node features of shape [batch_size, num_nodes, c_in]\n",
    "            adj_matrix - Batch of adjacency matrices of the graph. If there is an edge from i to j, adj_matrix[b,i,j]=1 else 0.\n",
    "                         Supports directed edges by non-symmetric matrices. Assumes to already have added the identity connections. \n",
    "                         Shape: [batch_size, num_nodes, num_nodes]\n",
    "        \"\"\"\n",
    "        data = Data(x=x, edge_index=edge_index)\n",
    "        \n",
    "        G = to_networkx(data)\n",
    "        adjacency_matrix = nx.to_numpy_array(G, nodelist=G.nodes() )\n",
    "        \n",
    "        node_feats = x\n",
    "        adj_matrix = torch.tensor(adjacency_matrix)\n",
    "        \n",
    "        # Num neighbours = number of incoming edges\n",
    "        num_neighbours = adj_matrix.sum(dim=-1, keepdims=True)\n",
    "        node_feats = self.projection(node_feats)\n",
    "        node_feats = torch.bmm(adj_matrix, node_feats)\n",
    "        node_feats = node_feats / num_neighbours\n",
    "        return node_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the forward pass of this GCN-Layer from the batched-graph above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GCN in PyG way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(aggr='add')  # \"Add\" aggregation (Step 5).\n",
    "        self.lin = Linear(in_channels, out_channels, bias=False)\n",
    "        self.bias = Parameter(torch.empty(out_channels))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin.reset_parameters()\n",
    "        self.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        # Step 1: Add self-loops to the adjacency matrix.\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        # Step 2: Linearly transform node feature matrix.\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # Step 3: Compute normalization.\n",
    "        row, col = edge_index\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        # Step 4-5: Start propagating messages.\n",
    "        out = self.propagate(edge_index, x=x, norm=norm)\n",
    "\n",
    "        # Step 6: Apply a final bias vector.\n",
    "        out += self.bias\n",
    "\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        # x_j has shape [E, out_channels]\n",
    "\n",
    "        # Step 4: Normalize node features.\n",
    "        return norm.view(-1, 1) * x_j\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formalism\n",
    "\n",
    "A significant chunk of the code is taken from : https://github.com/chaitjo/geometric-gnn-dojo/blob/main/geometric_gnn_101.ipynb\n",
    "\n",
    "Firstly, let us formalise our molecular property prediction pipeline. (Our notation will mostly follow what has been introduced in the lectures, but we do make some different choices for variable names.)\n",
    "\n",
    "### Graph \n",
    "Consider a molecular graph $\\mathcal{G} = \\left( \\mathcal{V}, \\mathcal{E} \\right)$, where $\\mathcal{V}$ is a set of $n$ nodes, and $\\mathcal{E}$ is a set of edges associated with the nodes. For each node $i \\in \\mathcal{V}$, we are given a $d_n$-dimensional initial feature vector $h_i \\in \\mathbb{R}^{d_n}$.\n",
    "For each edge $(i, j) \\in \\mathcal{E}$, we are given a $d_e$-dimensional initial feature vector $e_{ij} \\in \\mathbb{R}^{d_e}$. For Jet graphs, $d_n = 23, d_e = 1$.\n",
    "\n",
    "### Label/target \n",
    "Associated with each graph $\\mathcal{G}$ is a scalar target or label $y \\in \\mathbb{R}^{1}$, which we would like to predict. \n",
    "\n",
    "We will design a Message Passing Neural Network for graph property prediction to do this. Our MPNN will consist of several layers of message passing, followed by a global pooling and prediction head.\n",
    "\n",
    "### MPNN Layer \n",
    "The Message Passing operation iteratively updates node features $h_i^{\\ell} \\in \\mathbb{R}^d$ from layer $\\ell$ to layer $\\ell+1$ via the following equation:\n",
    "$$\n",
    "h_i^{\\ell+1} = \\phi \\Bigg( h_i^{\\ell}, \\oplus_{j \\in \\mathcal{N}_i} \\Big( \\psi \\left( h_i^{\\ell}, h_j^{\\ell}, e_{ij} \\right) \\Big) \\Bigg),\n",
    "$$\n",
    "where $\\psi, \\phi$ are Multi-Layer Perceptrons (MLPs), and $\\oplus$ is a permutation-invariant local neighborhood aggregation function such as summation, maximization, or averaging.\n",
    "\n",
    "Let us break down the MPNN layer into three pedagogical steps:\n",
    "- **Step (1): Message.** For each pair of linked nodes $i, j$, the network first computes a message $m_{ij} =  \\psi \\left( h_i^{\\ell}, h_j^{\\ell}, e_{ij} \\right)$. The MLP $\\psi: \\mathbb{R}^{2d + d_e} → \\mathbb{R}^d$ takes as input the concatenation of the feature vectors from the source node, destination node, and edge.\n",
    "    - Note that for the first layer $\\ell=0$, $h_i^{\\ell=0} = W_{in} \\left( h_i \\right)$, where $W_{in} \\in \\mathbb{R}^{d_n}  \\rightarrow \\mathbb{R}^{d}$ is a simple linear projection (`torch.nn.Linear`) for the initial node features to hidden dimension $d$.\n",
    "- **Step (2): Aggregate.** At each node $i$, the incoming messages from all its neighbors are then aggregated as $m_{i} = \\oplus_{{j \\in \\mathcal{N}_i}} \\left( m_{ij} \\right)$, where $\\oplus$ is a permutation-invariant function. We will use summation, i.e. $\\oplus_{{j \\in \\mathcal{N}_i}} = \\sum_{{j \\in \\mathcal{N}_i}}$.\n",
    "- **Step (3): Update.** Finally, the network updates the node feature vector $h_i^{\\ell+1} = \\phi \\left( h_i^{\\ell}, m_i \\right)$, by concatenating the aggregated message $m_i$ and the previous node feature vector $h_i^{\\ell}$, and passing them through an MLP $\\phi: \\mathbb{R}^{2d} → \\mathbb{R}^{d}$.\n",
    "\n",
    "### Global Pooling and Prediction Head\n",
    "After $L$ layers of message passing, we obtain the final node features $h_i^{\\ell=L}$. As we have a single target $y$ per graph, we must pool all node features into a single graph feature or graph embedding $h_G \\in \\mathbb{R}^d$ via another permutation-invariant function $R$, sometimes called the 'readout' function, as follows:\n",
    "$$\n",
    "h_G = R_{i \\in \\mathcal{V}} \\left( h_i^{\\ell=L} \\right). \n",
    "$$ \n",
    "We will use global average pooling over all node features, i.e.\n",
    "$$\n",
    "h_G = \\frac{1}{|\\mathcal{V}|} \\sum_{i \\in \\mathcal{V}} h_i^{\\ell=L}. \n",
    "$$\n",
    "\n",
    "The graph embedding $h_G$ is passed through a linear prediction head $W_{pred} \\in \\mathbb{R}^{d} \\rightarrow \\mathbb{R}^1$ to obtain the overall prediction $\\hat y \\in \\mathbb{R}^1$:\n",
    "$$\n",
    "\\hat y = W_{pred} \\left( h_G \\right).\n",
    "$$ \n",
    "\n",
    "### Loss Function\n",
    "Our MPNN graph property prediction model can be trained end-to-end via minimizing the standard mean-squared error loss for regression:\n",
    "$$\n",
    "\\mathcal{L}_{MSE} = \\lVert y - \\hat y \\rVert^2_2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding the basic Message Passing Neural Network Layer\n",
    "\n",
    "We will code up the **MPNN Layer** first. \n",
    "\n",
    "To do so, we will inherit from the `MessagePassing` base class, which automatically takes care of message propagation and is extremely useful to develop advanced GNN models. To implement a custom MPNN, the user only needs to define the behaviour of the `message` (i.e. $\\psi$), the `aggregate`(i.e. $\\oplus$), and `update` (i.e. $\\phi$) functions. You may also refer to the [PyG documentation](https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html) for implementing custom message passing layers.\n",
    "\n",
    "Below, we provide the implementation of a standard MPNN layer as an example, with extensive inline comments to help you figure out what is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPNNLayer(MessagePassing):\n",
    "    def __init__(self, emb_dim=64, edge_dim=4, aggr='add'):\n",
    "        \"\"\"Message Passing Neural Network Layer\n",
    "\n",
    "        Args:\n",
    "            emb_dim: (int) - hidden dimension `d`\n",
    "            edge_dim: (int) - edge feature dimension `d_e`\n",
    "            aggr: (str) - aggregation function `\\oplus` (sum/mean/max)\n",
    "        \"\"\"\n",
    "        # Set the aggregation function\n",
    "        super(MPNNLayer, self).__init__(aggr=aggr)\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.edge_dim = edge_dim\n",
    "        \n",
    "        #self.node_dim = -1\n",
    "        \n",
    "\n",
    "        # MLP `\\psi` for computing messages `m_ij`\n",
    "        # Implemented as a stack of Linear->BN->ReLU->Linear->BN->ReLU\n",
    "        # dims: (2d + d_e) -> d\n",
    "        self.mlp_msg = Sequential(\n",
    "            Linear(2*emb_dim + edge_dim, emb_dim), BatchNorm1d(emb_dim), ReLU(),\n",
    "            Linear(emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU()\n",
    "          )\n",
    "        \n",
    "        # MLP `\\phi` for computing updated node features `h_i^{l+1}`\n",
    "        # Implemented as a stack of Linear->BN->ReLU->Linear->BN->ReLU\n",
    "        # dims: 2d -> d\n",
    "        self.mlp_upd = Sequential(\n",
    "            Linear(2*emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU(), \n",
    "            Linear(emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU()\n",
    "          )\n",
    "\n",
    "    def forward(self, h, edge_index, edge_attr):\n",
    "        \"\"\"\n",
    "        The forward pass updates node features `h` via one round of message passing.\n",
    "\n",
    "        As our MPNNLayer class inherits from the PyG MessagePassing parent class,\n",
    "        we simply need to call the `propagate()` function which starts the \n",
    "        message passing procedure: `message()` -> `aggregate()` -> `update()`.\n",
    "        \n",
    "        The MessagePassing class handles most of the logic for the implementation.\n",
    "        To build custom GNNs, we only need to define our own `message()`, \n",
    "        `aggregate()`, and `update()` functions (defined subsequently).\n",
    "\n",
    "        Args:\n",
    "            h: (n, d) - initial node features\n",
    "            edge_index: (e, 2) - pairs of edges (i, j)\n",
    "            edge_attr: (e, d_e) - edge features\n",
    "\n",
    "        Returns:\n",
    "            out: (n, d) - updated node features\n",
    "        \"\"\"\n",
    "        out = self.propagate(edge_index=edge_index, h=h, edge_attr=edge_attr)\n",
    "        return out\n",
    "\n",
    "    def message(self, h_i, h_j, edge_attr):\n",
    "        \"\"\"Step (1) Message\n",
    "\n",
    "        The `message()` function constructs messages from source nodes j \n",
    "        to destination nodes i for each edge (i, j) in `edge_index`.\n",
    "\n",
    "        The arguments can be a bit tricky to understand: `message()` can take \n",
    "        any arguments that were initially passed to `propagate`. Additionally, \n",
    "        we can differentiate destination nodes and source nodes by appending \n",
    "        `_i` or `_j` to the variable name, e.g. for the node features `h`, we\n",
    "        can use `h_i` and `h_j`. \n",
    "        \n",
    "        This part is critical to understand as the `message()` function\n",
    "        constructs messages for each edge in the graph. The indexing of the\n",
    "        original node features `h` (or other node variables) is handled under\n",
    "        the hood by PyG.\n",
    "\n",
    "        Args:\n",
    "            h_i: (e, d) - destination node features\n",
    "            h_j: (e, d) - source node features\n",
    "            edge_attr: (e, d_e) - edge features\n",
    "        \n",
    "        Returns:\n",
    "            msg: (e, d) - messages `m_ij` passed through MLP `\\psi`\n",
    "        \"\"\"\n",
    "        \n",
    "        msg = torch.cat([h_i, h_j, edge_attr], dim=-1)\n",
    "        return self.mlp_msg(msg)\n",
    "    \n",
    "    def aggregate(self, inputs, index):\n",
    "        \"\"\"Step (2) Aggregate\n",
    "\n",
    "        The `aggregate` function aggregates the messages from neighboring nodes,\n",
    "        according to the chosen aggregation function ('sum' by default).\n",
    "\n",
    "        Args:\n",
    "            inputs: (e, d) - messages `m_ij` from destination to source nodes\n",
    "            index: (e, 1) - list of source nodes for each edge/message in `input`\n",
    "\n",
    "        Returns:\n",
    "            aggr_out: (n, d) - aggregated messages `m_i`\n",
    "        \"\"\"\n",
    "        \n",
    "        out = scatter(inputs, index, dim=0, reduce=self.aggr)\n",
    "       \n",
    "        return out#scatter(inputs, index, dim=self.node_dim, reduce=self.aggr)\n",
    "    \n",
    "    def update(self, aggr_out, h):\n",
    "        \"\"\"\n",
    "        Step (3) Update\n",
    "\n",
    "        The `update()` function computes the final node features by combining the \n",
    "        aggregated messages with the initial node features.\n",
    "\n",
    "        `update()` takes the first argument `aggr_out`, the result of `aggregate()`, \n",
    "        as well as any optional arguments that were initially passed to \n",
    "        `propagate()`. E.g. in this case, we additionally pass `h`.\n",
    "\n",
    "        Args:\n",
    "            aggr_out: (n, d) - aggregated messages `m_i`\n",
    "            h: (n, d) - initial node features\n",
    "\n",
    "        Returns:\n",
    "            upd_out: (n, d) - updated node features passed through MLP `\\phi`\n",
    "        \"\"\"\n",
    "        \n",
    "        upd_out = torch.cat([h, aggr_out], dim=-1)\n",
    "        return self.mlp_upd(upd_out)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}(emb_dim={self.emb_dim}, aggr={self.aggr})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have defined a **Message Passing layer** following the equation we had introduced previously. Let us use this layer to code up the full **MPNN graph property prediction model**. This model will take as input molecular graphs, process them via multiple MPNN layers, and predict a single property for each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPNNModel(Module):\n",
    "    def __init__(self, num_layers=4, emb_dim=64, in_dim=11, edge_dim=4, out_dim=1):\n",
    "        \"\"\"Message Passing Neural Network model for graph property prediction\n",
    "\n",
    "        Args:\n",
    "            num_layers: (int) - number of message passing layers `L`\n",
    "            emb_dim: (int) - hidden dimension `d`\n",
    "            in_dim: (int) - initial node feature dimension `d_n`\n",
    "            edge_dim: (int) - edge feature dimension `d_e`\n",
    "            out_dim: (int) - output dimension (fixed to 1)\n",
    "        \"\"\"\n",
    "        super(MPNNModel, self).__init__()\n",
    "        \n",
    "        # Linear projection for initial node features\n",
    "        # dim: d_n -> d\n",
    "        self.lin_in = Linear(in_dim, emb_dim)\n",
    "        \n",
    "        # Stack of MPNN layers\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for layer in range(num_layers):\n",
    "            self.convs.append(MPNNLayer(emb_dim, edge_dim, aggr='add'))\n",
    "        \n",
    "        # Global pooling/readout function `R` (mean pooling)\n",
    "        # PyG handles the underlying logic via `global_mean_pool()`\n",
    "        self.pool = global_mean_pool\n",
    "\n",
    "        # Linear prediction head\n",
    "        # dim: d -> out_dim\n",
    "        self.lin_pred = Linear(emb_dim, out_dim)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: (PyG.Data) - batch of PyG graphs\n",
    "\n",
    "        Returns: \n",
    "            out: (batch_size, out_dim) - prediction for each graph\n",
    "        \"\"\"\n",
    "        h = self.lin_in(data.x) # (n, d_n) -> (n, d)\n",
    "        \n",
    "        for conv in self.convs:\n",
    "            h = h + conv(h = h, edge_index = data.edge_index, edge_attr = data.edge_deltaR) # (n, d) -> (n, d)\n",
    "            # Note that we add a residual connection after each MPNN layer\n",
    "\n",
    "        h_graph = self.pool(h, data.batch) # (n, d) -> (batch_size, d)\n",
    "\n",
    "        out = self.lin_pred(h_graph) # (batch_size, d) -> (batch_size, 1)\n",
    "\n",
    "        return out.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"144.766pt\" height=\"76.934pt\" viewBox=\"0 0 144.766 76.934\" version=\"1.1\">\n",
       "<defs>\n",
       "<g>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-0\">\n",
       "<path style=\"stroke:none;\" d=\"\"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-1\">\n",
       "<path style=\"stroke:none;\" d=\"M 1.765625 -4.40625 L 0.375 -4.296875 L 0.375 -3.984375 C 1.015625 -3.984375 1.109375 -3.921875 1.109375 -3.4375 L 1.109375 -0.75 C 1.109375 -0.3125 1 -0.3125 0.328125 -0.3125 L 0.328125 0 C 0.640625 -0.015625 1.1875 -0.03125 1.421875 -0.03125 C 1.78125 -0.03125 2.125 -0.015625 2.46875 0 L 2.46875 -0.3125 C 1.796875 -0.3125 1.765625 -0.359375 1.765625 -0.75 Z M 1.796875 -6.140625 C 1.796875 -6.453125 1.5625 -6.671875 1.28125 -6.671875 C 0.96875 -6.671875 0.75 -6.40625 0.75 -6.140625 C 0.75 -5.875 0.96875 -5.609375 1.28125 -5.609375 C 1.5625 -5.609375 1.796875 -5.828125 1.796875 -6.140625 Z M 1.796875 -6.140625 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-2\">\n",
       "<path style=\"stroke:none;\" d=\"M 1.09375 -3.421875 L 1.09375 -0.75 C 1.09375 -0.3125 0.984375 -0.3125 0.3125 -0.3125 L 0.3125 0 C 0.671875 -0.015625 1.171875 -0.03125 1.453125 -0.03125 C 1.703125 -0.03125 2.21875 -0.015625 2.5625 0 L 2.5625 -0.3125 C 1.890625 -0.3125 1.78125 -0.3125 1.78125 -0.75 L 1.78125 -2.59375 C 1.78125 -3.625 2.5 -4.1875 3.125 -4.1875 C 3.765625 -4.1875 3.875 -3.65625 3.875 -3.078125 L 3.875 -0.75 C 3.875 -0.3125 3.765625 -0.3125 3.09375 -0.3125 L 3.09375 0 C 3.4375 -0.015625 3.953125 -0.03125 4.21875 -0.03125 C 4.46875 -0.03125 5 -0.015625 5.328125 0 L 5.328125 -0.3125 C 4.8125 -0.3125 4.5625 -0.3125 4.5625 -0.609375 L 4.5625 -2.515625 C 4.5625 -3.375 4.5625 -3.671875 4.25 -4.03125 C 4.109375 -4.203125 3.78125 -4.40625 3.203125 -4.40625 C 2.46875 -4.40625 2 -3.984375 1.71875 -3.359375 L 1.71875 -4.40625 L 0.3125 -4.296875 L 0.3125 -3.984375 C 1.015625 -3.984375 1.09375 -3.921875 1.09375 -3.421875 Z M 1.09375 -3.421875 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-3\">\n",
       "<path style=\"stroke:none;\" d=\"M 3.78125 -0.546875 L 3.78125 0.109375 L 5.25 0 L 5.25 -0.3125 C 4.5625 -0.3125 4.46875 -0.375 4.46875 -0.875 L 4.46875 -6.921875 L 3.046875 -6.8125 L 3.046875 -6.5 C 3.734375 -6.5 3.8125 -6.4375 3.8125 -5.9375 L 3.8125 -3.78125 C 3.53125 -4.140625 3.09375 -4.40625 2.5625 -4.40625 C 1.390625 -4.40625 0.34375 -3.421875 0.34375 -2.140625 C 0.34375 -0.875 1.3125 0.109375 2.453125 0.109375 C 3.09375 0.109375 3.53125 -0.234375 3.78125 -0.546875 Z M 3.78125 -3.21875 L 3.78125 -1.171875 C 3.78125 -1 3.78125 -0.984375 3.671875 -0.8125 C 3.375 -0.328125 2.9375 -0.109375 2.5 -0.109375 C 2.046875 -0.109375 1.6875 -0.375 1.453125 -0.75 C 1.203125 -1.15625 1.171875 -1.71875 1.171875 -2.140625 C 1.171875 -2.5 1.1875 -3.09375 1.46875 -3.546875 C 1.6875 -3.859375 2.0625 -4.1875 2.609375 -4.1875 C 2.953125 -4.1875 3.375 -4.03125 3.671875 -3.59375 C 3.78125 -3.421875 3.78125 -3.40625 3.78125 -3.21875 Z M 3.78125 -3.21875 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-4\">\n",
       "<path style=\"stroke:none;\" d=\"M 1.109375 -2.515625 C 1.171875 -4 2.015625 -4.25 2.359375 -4.25 C 3.375 -4.25 3.484375 -2.90625 3.484375 -2.515625 Z M 1.109375 -2.296875 L 3.890625 -2.296875 C 4.109375 -2.296875 4.140625 -2.296875 4.140625 -2.515625 C 4.140625 -3.5 3.59375 -4.46875 2.359375 -4.46875 C 1.203125 -4.46875 0.28125 -3.4375 0.28125 -2.1875 C 0.28125 -0.859375 1.328125 0.109375 2.46875 0.109375 C 3.6875 0.109375 4.140625 -1 4.140625 -1.1875 C 4.140625 -1.28125 4.0625 -1.3125 4 -1.3125 C 3.921875 -1.3125 3.890625 -1.25 3.875 -1.171875 C 3.53125 -0.140625 2.625 -0.140625 2.53125 -0.140625 C 2.03125 -0.140625 1.640625 -0.4375 1.40625 -0.8125 C 1.109375 -1.28125 1.109375 -1.9375 1.109375 -2.296875 Z M 1.109375 -2.296875 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-5\">\n",
       "<path style=\"stroke:none;\" d=\"M 2.859375 -2.34375 C 3.15625 -2.71875 3.53125 -3.203125 3.78125 -3.46875 C 4.09375 -3.828125 4.5 -3.984375 4.96875 -3.984375 L 4.96875 -4.296875 C 4.703125 -4.28125 4.40625 -4.265625 4.140625 -4.265625 C 3.84375 -4.265625 3.3125 -4.28125 3.1875 -4.296875 L 3.1875 -3.984375 C 3.40625 -3.96875 3.484375 -3.84375 3.484375 -3.671875 C 3.484375 -3.515625 3.375 -3.390625 3.328125 -3.328125 L 2.71875 -2.546875 L 1.9375 -3.5625 C 1.84375 -3.65625 1.84375 -3.671875 1.84375 -3.734375 C 1.84375 -3.890625 2 -3.984375 2.1875 -3.984375 L 2.1875 -4.296875 C 1.9375 -4.28125 1.28125 -4.265625 1.109375 -4.265625 C 0.90625 -4.265625 0.4375 -4.28125 0.171875 -4.296875 L 0.171875 -3.984375 C 0.875 -3.984375 0.875 -3.984375 1.34375 -3.375 L 2.328125 -2.09375 L 1.390625 -0.90625 C 0.921875 -0.328125 0.328125 -0.3125 0.125 -0.3125 L 0.125 0 C 0.375 -0.015625 0.6875 -0.03125 0.953125 -0.03125 C 1.234375 -0.03125 1.65625 -0.015625 1.890625 0 L 1.890625 -0.3125 C 1.671875 -0.34375 1.609375 -0.46875 1.609375 -0.625 C 1.609375 -0.84375 1.890625 -1.171875 2.5 -1.890625 L 3.265625 -0.890625 C 3.34375 -0.78125 3.46875 -0.625 3.46875 -0.5625 C 3.46875 -0.46875 3.375 -0.3125 3.109375 -0.3125 L 3.109375 0 C 3.40625 -0.015625 3.96875 -0.03125 4.1875 -0.03125 C 4.453125 -0.03125 4.84375 -0.015625 5.140625 0 L 5.140625 -0.3125 C 4.609375 -0.3125 4.421875 -0.328125 4.203125 -0.625 Z M 2.859375 -2.34375 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-6\">\n",
       "<path style=\"stroke:none;\" d=\"M 1.71875 -3.75 L 1.71875 -4.40625 L 0.28125 -4.296875 L 0.28125 -3.984375 C 0.984375 -3.984375 1.0625 -3.921875 1.0625 -3.484375 L 1.0625 1.171875 C 1.0625 1.625 0.953125 1.625 0.28125 1.625 L 0.28125 1.9375 C 0.625 1.921875 1.140625 1.90625 1.390625 1.90625 C 1.671875 1.90625 2.171875 1.921875 2.515625 1.9375 L 2.515625 1.625 C 1.859375 1.625 1.75 1.625 1.75 1.171875 L 1.75 -0.59375 C 1.796875 -0.421875 2.21875 0.109375 2.96875 0.109375 C 4.15625 0.109375 5.1875 -0.875 5.1875 -2.15625 C 5.1875 -3.421875 4.234375 -4.40625 3.109375 -4.40625 C 2.328125 -4.40625 1.90625 -3.96875 1.71875 -3.75 Z M 1.75 -1.140625 L 1.75 -3.359375 C 2.03125 -3.875 2.515625 -4.15625 3.03125 -4.15625 C 3.765625 -4.15625 4.359375 -3.28125 4.359375 -2.15625 C 4.359375 -0.953125 3.671875 -0.109375 2.9375 -0.109375 C 2.53125 -0.109375 2.15625 -0.3125 1.890625 -0.71875 C 1.75 -0.921875 1.75 -0.9375 1.75 -1.140625 Z M 1.75 -1.140625 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-7\">\n",
       "<path style=\"stroke:none;\" d=\"M 3.890625 -0.78125 L 3.890625 0.109375 L 5.328125 0 L 5.328125 -0.3125 C 4.640625 -0.3125 4.5625 -0.375 4.5625 -0.875 L 4.5625 -4.40625 L 3.09375 -4.296875 L 3.09375 -3.984375 C 3.78125 -3.984375 3.875 -3.921875 3.875 -3.421875 L 3.875 -1.65625 C 3.875 -0.78125 3.390625 -0.109375 2.65625 -0.109375 C 1.828125 -0.109375 1.78125 -0.578125 1.78125 -1.09375 L 1.78125 -4.40625 L 0.3125 -4.296875 L 0.3125 -3.984375 C 1.09375 -3.984375 1.09375 -3.953125 1.09375 -3.078125 L 1.09375 -1.578125 C 1.09375 -0.796875 1.09375 0.109375 2.609375 0.109375 C 3.171875 0.109375 3.609375 -0.171875 3.890625 -0.78125 Z M 3.890625 -0.78125 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-8\">\n",
       "<path style=\"stroke:none;\" d=\"M 1.71875 -3.984375 L 3.15625 -3.984375 L 3.15625 -4.296875 L 1.71875 -4.296875 L 1.71875 -6.125 L 1.46875 -6.125 C 1.46875 -5.3125 1.171875 -4.25 0.1875 -4.203125 L 0.1875 -3.984375 L 1.03125 -3.984375 L 1.03125 -1.234375 C 1.03125 -0.015625 1.96875 0.109375 2.328125 0.109375 C 3.03125 0.109375 3.3125 -0.59375 3.3125 -1.234375 L 3.3125 -1.796875 L 3.0625 -1.796875 L 3.0625 -1.25 C 3.0625 -0.515625 2.765625 -0.140625 2.390625 -0.140625 C 1.71875 -0.140625 1.71875 -1.046875 1.71875 -1.21875 Z M 1.71875 -3.984375 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-9\">\n",
       "<path style=\"stroke:none;\" d=\"M 4.578125 -3.1875 C 4.578125 -3.984375 4.53125 -4.78125 4.1875 -5.515625 C 3.734375 -6.484375 2.90625 -6.640625 2.5 -6.640625 C 1.890625 -6.640625 1.171875 -6.375 0.75 -5.453125 C 0.4375 -4.765625 0.390625 -3.984375 0.390625 -3.1875 C 0.390625 -2.4375 0.421875 -1.546875 0.84375 -0.78125 C 1.265625 0.015625 2 0.21875 2.484375 0.21875 C 3.015625 0.21875 3.78125 0.015625 4.21875 -0.9375 C 4.53125 -1.625 4.578125 -2.40625 4.578125 -3.1875 Z M 2.484375 0 C 2.09375 0 1.5 -0.25 1.328125 -1.203125 C 1.21875 -1.796875 1.21875 -2.71875 1.21875 -3.3125 C 1.21875 -3.953125 1.21875 -4.609375 1.296875 -5.140625 C 1.484375 -6.328125 2.234375 -6.421875 2.484375 -6.421875 C 2.8125 -6.421875 3.46875 -6.234375 3.65625 -5.25 C 3.765625 -4.6875 3.765625 -3.9375 3.765625 -3.3125 C 3.765625 -2.5625 3.765625 -1.890625 3.65625 -1.25 C 3.5 -0.296875 2.9375 0 2.484375 0 Z M 2.484375 0 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-10\">\n",
       "<path style=\"stroke:none;\" d=\"M 4.46875 -2 C 4.46875 -3.1875 3.65625 -4.1875 2.578125 -4.1875 C 2.109375 -4.1875 1.671875 -4.03125 1.3125 -3.671875 L 1.3125 -5.625 C 1.515625 -5.5625 1.84375 -5.5 2.15625 -5.5 C 3.390625 -5.5 4.09375 -6.40625 4.09375 -6.53125 C 4.09375 -6.59375 4.0625 -6.640625 3.984375 -6.640625 C 3.984375 -6.640625 3.953125 -6.640625 3.90625 -6.609375 C 3.703125 -6.515625 3.21875 -6.3125 2.546875 -6.3125 C 2.15625 -6.3125 1.6875 -6.390625 1.21875 -6.59375 C 1.140625 -6.625 1.125 -6.625 1.109375 -6.625 C 1 -6.625 1 -6.546875 1 -6.390625 L 1 -3.4375 C 1 -3.265625 1 -3.1875 1.140625 -3.1875 C 1.21875 -3.1875 1.234375 -3.203125 1.28125 -3.265625 C 1.390625 -3.421875 1.75 -3.96875 2.5625 -3.96875 C 3.078125 -3.96875 3.328125 -3.515625 3.40625 -3.328125 C 3.5625 -2.953125 3.59375 -2.578125 3.59375 -2.078125 C 3.59375 -1.71875 3.59375 -1.125 3.34375 -0.703125 C 3.109375 -0.3125 2.734375 -0.0625 2.28125 -0.0625 C 1.5625 -0.0625 0.984375 -0.59375 0.8125 -1.171875 C 0.84375 -1.171875 0.875 -1.15625 0.984375 -1.15625 C 1.3125 -1.15625 1.484375 -1.40625 1.484375 -1.640625 C 1.484375 -1.890625 1.3125 -2.140625 0.984375 -2.140625 C 0.84375 -2.140625 0.5 -2.0625 0.5 -1.609375 C 0.5 -0.75 1.1875 0.21875 2.296875 0.21875 C 3.453125 0.21875 4.46875 -0.734375 4.46875 -2 Z M 4.46875 -2 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-11\">\n",
       "<path style=\"stroke:none;\" d=\"M 2.9375 -6.375 C 2.9375 -6.625 2.9375 -6.640625 2.703125 -6.640625 C 2.078125 -6 1.203125 -6 0.890625 -6 L 0.890625 -5.6875 C 1.09375 -5.6875 1.671875 -5.6875 2.1875 -5.953125 L 2.1875 -0.78125 C 2.1875 -0.421875 2.15625 -0.3125 1.265625 -0.3125 L 0.953125 -0.3125 L 0.953125 0 C 1.296875 -0.03125 2.15625 -0.03125 2.5625 -0.03125 C 2.953125 -0.03125 3.828125 -0.03125 4.171875 0 L 4.171875 -0.3125 L 3.859375 -0.3125 C 2.953125 -0.3125 2.9375 -0.421875 2.9375 -0.78125 Z M 2.9375 -6.375 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-12\">\n",
       "<path style=\"stroke:none;\" d=\"M 4.75 -6.078125 C 4.828125 -6.1875 4.828125 -6.203125 4.828125 -6.421875 L 2.40625 -6.421875 C 1.203125 -6.421875 1.171875 -6.546875 1.140625 -6.734375 L 0.890625 -6.734375 L 0.5625 -4.6875 L 0.8125 -4.6875 C 0.84375 -4.84375 0.921875 -5.46875 1.0625 -5.59375 C 1.125 -5.65625 1.90625 -5.65625 2.03125 -5.65625 L 4.09375 -5.65625 C 3.984375 -5.5 3.203125 -4.40625 2.984375 -4.078125 C 2.078125 -2.734375 1.75 -1.34375 1.75 -0.328125 C 1.75 -0.234375 1.75 0.21875 2.21875 0.21875 C 2.671875 0.21875 2.671875 -0.234375 2.671875 -0.328125 L 2.671875 -0.84375 C 2.671875 -1.390625 2.703125 -1.9375 2.78125 -2.46875 C 2.828125 -2.703125 2.953125 -3.5625 3.40625 -4.171875 Z M 4.75 -6.078125 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-13\">\n",
       "<path style=\"stroke:none;\" d=\"M 1.265625 -0.765625 L 2.328125 -1.796875 C 3.875 -3.171875 4.46875 -3.703125 4.46875 -4.703125 C 4.46875 -5.84375 3.578125 -6.640625 2.359375 -6.640625 C 1.234375 -6.640625 0.5 -5.71875 0.5 -4.828125 C 0.5 -4.28125 1 -4.28125 1.03125 -4.28125 C 1.203125 -4.28125 1.546875 -4.390625 1.546875 -4.8125 C 1.546875 -5.0625 1.359375 -5.328125 1.015625 -5.328125 C 0.9375 -5.328125 0.921875 -5.328125 0.890625 -5.3125 C 1.109375 -5.96875 1.65625 -6.328125 2.234375 -6.328125 C 3.140625 -6.328125 3.5625 -5.515625 3.5625 -4.703125 C 3.5625 -3.90625 3.078125 -3.125 2.515625 -2.5 L 0.609375 -0.375 C 0.5 -0.265625 0.5 -0.234375 0.5 0 L 4.203125 0 L 4.46875 -1.734375 L 4.234375 -1.734375 C 4.171875 -1.4375 4.109375 -1 4 -0.84375 C 3.9375 -0.765625 3.28125 -0.765625 3.0625 -0.765625 Z M 1.265625 -0.765625 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-14\">\n",
       "<path style=\"stroke:none;\" d=\"M 2.890625 -3.515625 C 3.703125 -3.78125 4.28125 -4.46875 4.28125 -5.265625 C 4.28125 -6.078125 3.40625 -6.640625 2.453125 -6.640625 C 1.453125 -6.640625 0.6875 -6.046875 0.6875 -5.28125 C 0.6875 -4.953125 0.90625 -4.765625 1.203125 -4.765625 C 1.5 -4.765625 1.703125 -4.984375 1.703125 -5.28125 C 1.703125 -5.765625 1.234375 -5.765625 1.09375 -5.765625 C 1.390625 -6.265625 2.046875 -6.390625 2.40625 -6.390625 C 2.828125 -6.390625 3.375 -6.171875 3.375 -5.28125 C 3.375 -5.15625 3.34375 -4.578125 3.09375 -4.140625 C 2.796875 -3.65625 2.453125 -3.625 2.203125 -3.625 C 2.125 -3.609375 1.890625 -3.59375 1.8125 -3.59375 C 1.734375 -3.578125 1.671875 -3.5625 1.671875 -3.46875 C 1.671875 -3.359375 1.734375 -3.359375 1.90625 -3.359375 L 2.34375 -3.359375 C 3.15625 -3.359375 3.53125 -2.6875 3.53125 -1.703125 C 3.53125 -0.34375 2.84375 -0.0625 2.40625 -0.0625 C 1.96875 -0.0625 1.21875 -0.234375 0.875 -0.8125 C 1.21875 -0.765625 1.53125 -0.984375 1.53125 -1.359375 C 1.53125 -1.71875 1.265625 -1.921875 0.984375 -1.921875 C 0.734375 -1.921875 0.421875 -1.78125 0.421875 -1.34375 C 0.421875 -0.4375 1.34375 0.21875 2.4375 0.21875 C 3.65625 0.21875 4.5625 -0.6875 4.5625 -1.703125 C 4.5625 -2.515625 3.921875 -3.296875 2.890625 -3.515625 Z M 2.890625 -3.515625 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-15\">\n",
       "<path style=\"stroke:none;\" d=\"M 4.6875 -2.140625 C 4.6875 -3.40625 3.703125 -4.46875 2.5 -4.46875 C 1.25 -4.46875 0.28125 -3.375 0.28125 -2.140625 C 0.28125 -0.84375 1.3125 0.109375 2.484375 0.109375 C 3.6875 0.109375 4.6875 -0.875 4.6875 -2.140625 Z M 2.5 -0.140625 C 2.0625 -0.140625 1.625 -0.34375 1.359375 -0.8125 C 1.109375 -1.25 1.109375 -1.859375 1.109375 -2.21875 C 1.109375 -2.609375 1.109375 -3.140625 1.34375 -3.578125 C 1.609375 -4.03125 2.078125 -4.25 2.484375 -4.25 C 2.921875 -4.25 3.34375 -4.03125 3.609375 -3.59375 C 3.875 -3.171875 3.875 -2.59375 3.875 -2.21875 C 3.875 -1.859375 3.875 -1.3125 3.65625 -0.875 C 3.421875 -0.421875 2.984375 -0.140625 2.5 -0.140625 Z M 2.5 -0.140625 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-16\">\n",
       "<path style=\"stroke:none;\" d=\"M 1.625 -4.5625 C 1.171875 -4.859375 1.125 -5.1875 1.125 -5.359375 C 1.125 -5.96875 1.78125 -6.390625 2.484375 -6.390625 C 3.203125 -6.390625 3.84375 -5.875 3.84375 -5.15625 C 3.84375 -4.578125 3.453125 -4.109375 2.859375 -3.765625 Z M 3.078125 -3.609375 C 3.796875 -3.984375 4.28125 -4.5 4.28125 -5.15625 C 4.28125 -6.078125 3.40625 -6.640625 2.5 -6.640625 C 1.5 -6.640625 0.6875 -5.90625 0.6875 -4.96875 C 0.6875 -4.796875 0.703125 -4.34375 1.125 -3.875 C 1.234375 -3.765625 1.609375 -3.515625 1.859375 -3.34375 C 1.28125 -3.046875 0.421875 -2.5 0.421875 -1.5 C 0.421875 -0.453125 1.4375 0.21875 2.484375 0.21875 C 3.609375 0.21875 4.5625 -0.609375 4.5625 -1.671875 C 4.5625 -2.03125 4.453125 -2.484375 4.0625 -2.90625 C 3.875 -3.109375 3.71875 -3.203125 3.078125 -3.609375 Z M 2.078125 -3.1875 L 3.3125 -2.40625 C 3.59375 -2.21875 4.0625 -1.921875 4.0625 -1.3125 C 4.0625 -0.578125 3.3125 -0.0625 2.5 -0.0625 C 1.640625 -0.0625 0.921875 -0.671875 0.921875 -1.5 C 0.921875 -2.078125 1.234375 -2.71875 2.078125 -3.1875 Z M 2.078125 -3.1875 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-17\">\n",
       "<path style=\"stroke:none;\" d=\"M 2.9375 -1.640625 L 2.9375 -0.78125 C 2.9375 -0.421875 2.90625 -0.3125 2.171875 -0.3125 L 1.96875 -0.3125 L 1.96875 0 C 2.375 -0.03125 2.890625 -0.03125 3.3125 -0.03125 C 3.734375 -0.03125 4.25 -0.03125 4.671875 0 L 4.671875 -0.3125 L 4.453125 -0.3125 C 3.71875 -0.3125 3.703125 -0.421875 3.703125 -0.78125 L 3.703125 -1.640625 L 4.6875 -1.640625 L 4.6875 -1.953125 L 3.703125 -1.953125 L 3.703125 -6.484375 C 3.703125 -6.6875 3.703125 -6.75 3.53125 -6.75 C 3.453125 -6.75 3.421875 -6.75 3.34375 -6.625 L 0.28125 -1.953125 L 0.28125 -1.640625 Z M 2.984375 -1.953125 L 0.5625 -1.953125 L 2.984375 -5.671875 Z M 2.984375 -1.953125 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph1-0\">\n",
       "<path style=\"stroke:none;\" d=\"\"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph1-1\">\n",
       "<path style=\"stroke:none;\" d=\"M 1.5 -0.34375 C 1.515625 -0.15625 1.625 0.03125 1.84375 0.03125 C 1.9375 0.03125 2.203125 -0.03125 2.203125 -0.40625 L 2.203125 -0.65625 L 2.09375 -0.65625 L 2.09375 -0.40625 C 2.09375 -0.140625 1.984375 -0.109375 1.9375 -0.109375 C 1.796875 -0.109375 1.765625 -0.3125 1.765625 -0.34375 L 1.765625 -1.234375 C 1.765625 -1.421875 1.765625 -1.59375 1.609375 -1.765625 C 1.4375 -1.9375 1.203125 -2.015625 1 -2.015625 C 0.625 -2.015625 0.3125 -1.796875 0.3125 -1.5 C 0.3125 -1.375 0.40625 -1.296875 0.53125 -1.296875 C 0.65625 -1.296875 0.734375 -1.375 0.734375 -1.5 C 0.734375 -1.546875 0.703125 -1.703125 0.5 -1.703125 C 0.625 -1.859375 0.84375 -1.90625 0.984375 -1.90625 C 1.203125 -1.90625 1.46875 -1.734375 1.46875 -1.34375 L 1.46875 -1.171875 C 1.234375 -1.15625 0.921875 -1.140625 0.640625 -1.015625 C 0.296875 -0.859375 0.1875 -0.625 0.1875 -0.421875 C 0.1875 -0.0625 0.625 0.046875 0.90625 0.046875 C 1.203125 0.046875 1.40625 -0.125 1.5 -0.34375 Z M 1.46875 -1.078125 L 1.46875 -0.625 C 1.46875 -0.203125 1.140625 -0.046875 0.9375 -0.046875 C 0.71875 -0.046875 0.53125 -0.203125 0.53125 -0.4375 C 0.53125 -0.671875 0.71875 -1.046875 1.46875 -1.078125 Z M 1.46875 -1.078125 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph1-2\">\n",
       "<path style=\"stroke:none;\" d=\"M 1.703125 -0.25 L 1.703125 0.046875 L 2.359375 0 L 2.359375 -0.140625 C 2.046875 -0.140625 2.015625 -0.171875 2.015625 -0.390625 L 2.015625 -3.109375 L 1.375 -3.0625 L 1.375 -2.921875 C 1.6875 -2.921875 1.71875 -2.890625 1.71875 -2.671875 L 1.71875 -1.703125 C 1.59375 -1.859375 1.390625 -1.984375 1.15625 -1.984375 C 0.625 -1.984375 0.15625 -1.546875 0.15625 -0.96875 C 0.15625 -0.390625 0.59375 0.046875 1.109375 0.046875 C 1.390625 0.046875 1.59375 -0.109375 1.703125 -0.25 Z M 1.703125 -1.453125 L 1.703125 -0.53125 C 1.703125 -0.453125 1.703125 -0.4375 1.65625 -0.359375 C 1.515625 -0.140625 1.3125 -0.046875 1.125 -0.046875 C 0.921875 -0.046875 0.765625 -0.171875 0.65625 -0.34375 C 0.53125 -0.515625 0.53125 -0.78125 0.53125 -0.953125 C 0.53125 -1.125 0.53125 -1.390625 0.65625 -1.59375 C 0.765625 -1.734375 0.921875 -1.890625 1.171875 -1.890625 C 1.328125 -1.890625 1.515625 -1.8125 1.65625 -1.609375 C 1.703125 -1.53125 1.703125 -1.53125 1.703125 -1.453125 Z M 1.703125 -1.453125 \"/>\n",
       "</symbol>\n",
       "</g>\n",
       "<clipPath id=\"clip1\">\n",
       "  <path d=\"M 130 0 L 144.765625 0 L 144.765625 15 L 130 15 Z M 130 0 \"/>\n",
       "</clipPath>\n",
       "<clipPath id=\"clip2\">\n",
       "  <path d=\"M 130 20 L 144.765625 20 L 144.765625 35 L 130 35 Z M 130 20 \"/>\n",
       "</clipPath>\n",
       "<clipPath id=\"clip3\">\n",
       "  <path d=\"M 130 19 L 144.765625 19 L 144.765625 35 L 130 35 Z M 130 19 \"/>\n",
       "</clipPath>\n",
       "<clipPath id=\"clip4\">\n",
       "  <path d=\"M 59 62 L 74 62 L 74 76.933594 L 59 76.933594 Z M 59 62 \"/>\n",
       "</clipPath>\n",
       "<clipPath id=\"clip5\">\n",
       "  <path d=\"M 73 62 L 88 62 L 88 76.933594 L 73 76.933594 Z M 73 62 \"/>\n",
       "</clipPath>\n",
       "<clipPath id=\"clip6\">\n",
       "  <path d=\"M 73 62 L 89 62 L 89 76.933594 L 73 76.933594 Z M 73 62 \"/>\n",
       "</clipPath>\n",
       "<clipPath id=\"clip7\">\n",
       "  <path d=\"M 87 62 L 103 62 L 103 76.933594 L 87 76.933594 Z M 87 62 \"/>\n",
       "</clipPath>\n",
       "<clipPath id=\"clip8\">\n",
       "  <path d=\"M 102 62 L 117 62 L 117 76.933594 L 102 76.933594 Z M 102 62 \"/>\n",
       "</clipPath>\n",
       "<clipPath id=\"clip9\">\n",
       "  <path d=\"M 101 62 L 117 62 L 117 76.933594 L 101 76.933594 Z M 101 62 \"/>\n",
       "</clipPath>\n",
       "</defs>\n",
       "<g id=\"surface1\">\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"0\" y=\"10.745\"/>\n",
       "  <use xlink:href=\"#glyph0-2\" x=\"2.76761\" y=\"10.745\"/>\n",
       "  <use xlink:href=\"#glyph0-3\" x=\"8.302831\" y=\"10.745\"/>\n",
       "  <use xlink:href=\"#glyph0-4\" x=\"13.838051\" y=\"10.745\"/>\n",
       "  <use xlink:href=\"#glyph0-5\" x=\"18.265431\" y=\"10.745\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"0\" y=\"29.487\"/>\n",
       "  <use xlink:href=\"#glyph0-2\" x=\"2.76761\" y=\"29.487\"/>\n",
       "  <use xlink:href=\"#glyph0-6\" x=\"8.302831\" y=\"29.487\"/>\n",
       "  <use xlink:href=\"#glyph0-7\" x=\"13.838051\" y=\"29.487\"/>\n",
       "  <use xlink:href=\"#glyph0-8\" x=\"19.373272\" y=\"29.487\"/>\n",
       "</g>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -7.088313 55.276906 L 7.087469 55.276906 L 7.087469 69.448781 L -7.088313 69.448781 Z M -7.088313 55.276906 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-9\" x=\"35.777\" y=\"10.496\"/>\n",
       "</g>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(0%,67.83905%,93.728638%);fill-opacity:0.5;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -7.088313 35.433156 L 7.087469 35.433156 L 7.087469 49.605031 L -7.088313 49.605031 Z M -7.088313 35.433156 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-10\" x=\"35.777\" y=\"30.339\"/>\n",
       "</g>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 0.00153125 55.077688 L 0.00153125 50.265188 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.31879;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -1.19608 1.595281 C -1.094518 0.997625 -0.0007675 0.0991875 0.300014 0.00153125 C -0.0007675 -0.100031 -1.094518 -0.994563 -1.19608 -1.592219 \" transform=\"matrix(0,1,1,0,38.268,19.38358)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 7.087469 55.276906 L 21.259344 55.276906 L 21.259344 69.448781 L 7.087469 69.448781 Z M 7.087469 55.276906 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-9\" x=\"49.95\" y=\"10.496\"/>\n",
       "</g>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(0%,67.83905%,93.728638%);fill-opacity:0.5;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 7.087469 35.433156 L 21.259344 35.433156 L 21.259344 49.605031 L 7.087469 49.605031 Z M 7.087469 35.433156 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-11\" x=\"49.95\" y=\"30.339\"/>\n",
       "</g>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 14.173406 55.077688 L 14.173406 50.265188 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.31879;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -1.19608 1.593766 C -1.094518 0.99611 -0.0007675 0.0976725 0.300014 0.00001625 C -0.0007675 -0.101546 -1.094518 -0.996078 -1.19608 -1.593734 \" transform=\"matrix(0,1,1,0,52.44139,19.38358)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 21.259344 55.276906 L 35.435125 55.276906 L 35.435125 69.448781 L 21.259344 69.448781 Z M 21.259344 55.276906 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-11\" x=\"64.124\" y=\"10.496\"/>\n",
       "</g>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(100%,50%,0%);fill-opacity:0.5;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 21.259344 35.433156 L 35.435125 35.433156 L 35.435125 49.605031 L 21.259344 49.605031 Z M 21.259344 35.433156 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-12\" x=\"64.124\" y=\"30.339\"/>\n",
       "</g>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 28.345281 55.077688 L 28.345281 50.265188 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.31879;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -1.19608 1.592231 C -1.094518 0.994575 -0.0007675 0.100044 0.300014 -0.00151875 C -0.0007675 -0.099175 -1.094518 -0.997613 -1.19608 -1.595269 \" transform=\"matrix(0,1,1,0,66.6148,19.38358)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 35.435125 55.276906 L 49.607 55.276906 L 49.607 69.448781 L 35.435125 69.448781 Z M 35.435125 55.276906 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-9\" x=\"78.297\" y=\"10.496\"/>\n",
       "</g>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(0%,67.83905%,93.728638%);fill-opacity:0.5;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 35.435125 35.433156 L 49.607 35.433156 L 49.607 49.605031 L 35.435125 49.605031 Z M 35.435125 35.433156 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-13\" x=\"78.297\" y=\"30.339\"/>\n",
       "</g>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 42.521062 55.077688 L 42.521062 50.265188 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.31879;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -1.19608 1.594612 C -1.094518 0.996956 -0.0007675 0.0985187 0.300014 0.0008625 C -0.0007675 -0.1007 -1.094518 -0.995231 -1.19608 -1.592888 \" transform=\"matrix(0,1,1,0,80.7882,19.38358)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 49.607 55.276906 L 63.778875 55.276906 L 63.778875 69.448781 L 49.607 69.448781 Z M 49.607 55.276906 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-13\" x=\"92.47\" y=\"10.496\"/>\n",
       "</g>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(55.488586%,52.549744%,0%);fill-opacity:0.5;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 49.607 35.433156 L 63.778875 35.433156 L 63.778875 49.605031 L 49.607 49.605031 Z M 49.607 35.433156 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-14\" x=\"92.47\" y=\"30.339\"/>\n",
       "</g>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 56.692937 55.077688 L 56.692937 50.265188 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.31879;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -1.19608 1.593067 C -1.094518 0.995411 -0.0007675 0.10088 0.300014 -0.0006825 C -0.0007675 -0.0983388 -1.094518 -0.996776 -1.19608 -1.594433 \" transform=\"matrix(0,1,1,0,94.96162,19.38358)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 63.778875 55.276906 L 77.954656 55.276906 L 77.954656 69.448781 L 63.778875 69.448781 Z M 63.778875 55.276906 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-13\" x=\"106.643\" y=\"10.496\"/>\n",
       "</g>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(55.488586%,52.549744%,0%);fill-opacity:0.5;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 63.778875 35.433156 L 77.954656 35.433156 L 77.954656 49.605031 L 63.778875 49.605031 Z M 63.778875 35.433156 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-13\" x=\"106.643\" y=\"30.339\"/>\n",
       "</g>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 70.868719 55.077688 L 70.868719 50.265188 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.31879;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -1.19608 1.595469 C -1.094518 0.997812 -0.0007675 0.099375 0.300014 0.00171875 C -0.0007675 -0.0998438 -1.094518 -0.994375 -1.19608 -1.595938 \" transform=\"matrix(0,1,1,0,109.135,19.38358)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 77.954656 55.276906 L 92.126531 55.276906 L 92.126531 69.448781 L 77.954656 69.448781 Z M 77.954656 55.276906 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-14\" x=\"120.817\" y=\"10.496\"/>\n",
       "</g>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(92.549133%,0%,54.899597%);fill-opacity:0.5;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 77.954656 35.433156 L 92.126531 35.433156 L 92.126531 49.605031 L 77.954656 49.605031 Z M 77.954656 35.433156 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-11\" x=\"120.817\" y=\"30.339\"/>\n",
       "</g>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 85.040594 55.077688 L 85.040594 50.265188 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.31879;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -1.19608 1.593924 C -1.094518 0.996267 -0.0007675 0.09783 0.300014 0.00017375 C -0.0007675 -0.101389 -1.094518 -0.99592 -1.19608 -1.593576 \" transform=\"matrix(0,1,1,0,123.30842,19.38358)\"/>\n",
       "<g clip-path=\"url(#clip1)\" clip-rule=\"nonzero\">\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 92.126531 55.276906 L 106.302312 55.276906 L 106.302312 69.448781 L 92.126531 69.448781 Z M 92.126531 55.276906 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-14\" x=\"134.99\" y=\"10.496\"/>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip2)\" clip-rule=\"nonzero\">\n",
       "<path style=\" stroke:none;fill-rule:nonzero;fill:rgb(92.549133%,0%,54.899597%);fill-opacity:0.5;\" d=\"M 130.394531 34.214844 L 144.570312 34.214844 L 144.570312 20.042969 L 130.394531 20.042969 Z M 130.394531 34.214844 \"/>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3)\" clip-rule=\"nonzero\">\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 92.126531 35.433156 L 106.302312 35.433156 L 106.302312 49.605031 L 92.126531 49.605031 Z M 92.126531 35.433156 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-14\" x=\"134.99\" y=\"30.339\"/>\n",
       "</g>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 99.212469 55.077688 L 99.212469 50.265188 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.31879;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -1.19608 1.592399 C -1.094518 0.994742 -0.0007675 0.100211 0.300014 -0.00135125 C -0.0007675 -0.0990075 -1.094518 -0.997445 -1.19608 -1.595101 \" transform=\"matrix(0,1,1,0,137.48182,19.38358)\"/>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-15\" x=\"0\" y=\"71.743\"/>\n",
       "  <use xlink:href=\"#glyph0-7\" x=\"4.9813\" y=\"71.743\"/>\n",
       "  <use xlink:href=\"#glyph0-8\" x=\"10.516521\" y=\"71.743\"/>\n",
       "  <use xlink:href=\"#glyph0-6\" x=\"14.390976\" y=\"71.743\"/>\n",
       "  <use xlink:href=\"#glyph0-7\" x=\"19.926196\" y=\"71.743\"/>\n",
       "  <use xlink:href=\"#glyph0-8\" x=\"25.461417\" y=\"71.743\"/>\n",
       "</g>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 34.32575 17.007375 C 34.32575 19.483938 31.649969 21.49175 28.345281 21.49175 C 25.0445 21.49175 22.368719 19.483938 22.368719 17.007375 C 22.368719 14.530813 25.0445 12.526906 28.345281 12.526906 C 31.649969 12.526906 34.32575 14.530813 34.32575 17.007375 Z M 34.32575 17.007375 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph1-1\" x=\"63.003\" y=\"54.197\"/>\n",
       "  <use xlink:href=\"#glyph1-2\" x=\"65.244585\" y=\"54.197\"/>\n",
       "  <use xlink:href=\"#glyph1-2\" x=\"67.735434\" y=\"54.197\"/>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4)\" clip-rule=\"nonzero\">\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(0%,67.83905%,93.728638%);fill-opacity:0.5;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 21.259344 -7.086375 L 35.435125 -7.086375 L 35.435125 7.0855 L 21.259344 7.0855 Z M 21.259344 -7.086375 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-16\" x=\"64.124\" y=\"72.858\"/>\n",
       "</g>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 28.345281 12.327688 L 28.345281 7.745656 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.31879;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -1.196749 1.592231 C -1.095186 0.994575 -0.00143625 0.100044 0.299345 -0.00151875 C -0.00143625 -0.099175 -1.095186 -0.997613 -1.196749 -1.595269 \" transform=\"matrix(0,1,1,0,66.6148,61.90378)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 48.497625 17.007375 C 48.497625 19.483938 45.821844 21.49175 42.521062 21.49175 C 39.220281 21.49175 36.540594 19.483938 36.540594 17.007375 C 36.540594 14.530813 39.220281 12.526906 42.521062 12.526906 C 45.821844 12.526906 48.497625 14.530813 48.497625 17.007375 Z M 48.497625 17.007375 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph1-1\" x=\"77.176\" y=\"54.197\"/>\n",
       "  <use xlink:href=\"#glyph1-2\" x=\"79.417585\" y=\"54.197\"/>\n",
       "  <use xlink:href=\"#glyph1-2\" x=\"81.908434\" y=\"54.197\"/>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip5)\" clip-rule=\"nonzero\">\n",
       "<path style=\" stroke:none;fill-rule:nonzero;fill:rgb(100%,50%,0%);fill-opacity:0.5;\" d=\"M 73.703125 76.734375 L 87.875 76.734375 L 87.875 62.5625 L 73.703125 62.5625 Z M 73.703125 76.734375 \"/>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6)\" clip-rule=\"nonzero\">\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 35.435125 -7.086375 L 49.607 -7.086375 L 49.607 7.0855 L 35.435125 7.0855 Z M 35.435125 -7.086375 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-12\" x=\"78.297\" y=\"72.858\"/>\n",
       "</g>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 42.521062 12.327688 L 42.521062 7.745656 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.31879;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -1.196749 1.594612 C -1.095186 0.996956 -0.00143625 0.0985187 0.299345 0.0008625 C -0.00143625 -0.1007 -1.095186 -0.995231 -1.196749 -1.592888 \" transform=\"matrix(0,1,1,0,80.7882,61.90378)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 62.6695 17.007375 C 62.6695 19.483938 59.993719 21.49175 56.692937 21.49175 C 53.392156 21.49175 50.716375 19.483938 50.716375 17.007375 C 50.716375 14.530813 53.392156 12.526906 56.692937 12.526906 C 59.993719 12.526906 62.6695 14.530813 62.6695 17.007375 Z M 62.6695 17.007375 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph1-1\" x=\"91.349\" y=\"54.197\"/>\n",
       "  <use xlink:href=\"#glyph1-2\" x=\"93.590585\" y=\"54.197\"/>\n",
       "  <use xlink:href=\"#glyph1-2\" x=\"96.081434\" y=\"54.197\"/>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip7)\" clip-rule=\"nonzero\">\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(55.488586%,52.549744%,0%);fill-opacity:0.5;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 49.607 -7.086375 L 63.778875 -7.086375 L 63.778875 7.0855 L 49.607 7.0855 Z M 49.607 -7.086375 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-10\" x=\"92.47\" y=\"72.858\"/>\n",
       "</g>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 56.692937 12.327688 L 56.692937 7.745656 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.31879;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -1.196749 1.593067 C -1.095186 0.995411 -0.00143625 0.10088 0.299345 -0.0006825 C -0.00143625 -0.0983388 -1.095186 -0.996776 -1.196749 -1.594433 \" transform=\"matrix(0,1,1,0,94.96162,61.90378)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 76.845281 17.007375 C 76.845281 19.483938 74.1695 21.49175 70.868719 21.49175 C 67.564031 21.49175 64.88825 19.483938 64.88825 17.007375 C 64.88825 14.530813 67.564031 12.526906 70.868719 12.526906 C 74.1695 12.526906 76.845281 14.530813 76.845281 17.007375 Z M 76.845281 17.007375 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph1-1\" x=\"105.523\" y=\"54.197\"/>\n",
       "  <use xlink:href=\"#glyph1-2\" x=\"107.764585\" y=\"54.197\"/>\n",
       "  <use xlink:href=\"#glyph1-2\" x=\"110.255434\" y=\"54.197\"/>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip8)\" clip-rule=\"nonzero\">\n",
       "<path style=\" stroke:none;fill-rule:nonzero;fill:rgb(92.549133%,0%,54.899597%);fill-opacity:0.5;\" d=\"M 102.046875 76.734375 L 116.222656 76.734375 L 116.222656 62.5625 L 102.046875 62.5625 Z M 102.046875 76.734375 \"/>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip9)\" clip-rule=\"nonzero\">\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 63.778875 -7.086375 L 77.954656 -7.086375 L 77.954656 7.0855 L 63.778875 7.0855 Z M 63.778875 -7.086375 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-17\" x=\"106.643\" y=\"72.858\"/>\n",
       "</g>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 70.868719 12.327688 L 70.868719 7.745656 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.31879;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -1.196749 1.595469 C -1.095186 0.997812 -0.00143625 0.099375 0.299345 0.00171875 C -0.00143625 -0.0998438 -1.095186 -0.994375 -1.196749 -1.595938 \" transform=\"matrix(0,1,1,0,109.135,61.90378)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 0.00153125 35.233938 C 0.00153125 24.823781 28.345281 32.101125 28.345281 22.148 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.31879;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -1.194293 1.592231 C -1.096636 0.994575 0.00102 0.100044 0.297895 -0.00151875 C 0.00102 -0.099175 -1.096636 -0.997613 -1.194293 -1.595269 \" transform=\"matrix(0,1,1,0,66.6148,47.49898)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 14.173406 35.233938 C 14.173406 28.74175 28.345281 28.183156 28.345281 22.148 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.31879;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -1.194293 1.592231 C -1.096636 0.994575 0.00102 0.100044 0.297895 -0.00151875 C 0.00102 -0.099175 -1.096636 -0.997613 -1.194293 -1.595269 \" transform=\"matrix(0,1,1,0,66.6148,47.49898)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 28.345281 35.233938 C 28.345281 28.74175 42.521062 28.183156 42.521062 22.148 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.31879;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -1.194293 1.594612 C -1.096636 0.996956 0.00102 0.0985187 0.297895 0.0008625 C 0.00102 -0.1007 -1.096636 -0.995231 -1.194293 -1.592888 \" transform=\"matrix(0,1,1,0,80.7882,47.49898)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 42.521062 35.233938 C 42.521062 28.74175 28.345281 28.183156 28.345281 22.148 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.31879;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -1.194293 1.592231 C -1.096636 0.994575 0.00102 0.100044 0.297895 -0.00151875 C 0.00102 -0.099175 -1.096636 -0.997613 -1.194293 -1.595269 \" transform=\"matrix(0,1,1,0,66.6148,47.49898)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 56.692937 35.233938 C 56.692937 30.745656 56.692937 26.17925 56.692937 22.148 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.31879;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -1.194293 1.593067 C -1.096636 0.995411 0.00102 0.10088 0.297895 -0.0006825 C 0.00102 -0.0983388 -1.096636 -0.996776 -1.194293 -1.594433 \" transform=\"matrix(0,1,1,0,94.96162,47.49898)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 70.868719 35.233938 C 70.868719 28.74175 56.692937 28.183156 56.692937 22.148 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.31879;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -1.194293 1.593067 C -1.096636 0.995411 0.00102 0.10088 0.297895 -0.0006825 C 0.00102 -0.0983388 -1.096636 -0.996776 -1.194293 -1.594433 \" transform=\"matrix(0,1,1,0,94.96162,47.49898)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 85.040594 35.233938 C 85.040594 28.74175 70.868719 28.183156 70.868719 22.148 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.31879;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -1.194293 1.595469 C -1.096636 0.997812 0.00102 0.099375 0.297895 0.00171875 C 0.00102 -0.0998438 -1.096636 -0.994375 -1.194293 -1.595938 \" transform=\"matrix(0,1,1,0,109.135,47.49898)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 99.212469 35.233938 C 99.212469 24.823781 70.868719 32.101125 70.868719 22.148 \" transform=\"matrix(1,0,0,-1,38.268,69.648)\"/>\n",
       "<path style=\"fill:none;stroke-width:0.31879;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M -1.194293 1.595469 C -1.096636 0.997812 0.00102 0.099375 0.297895 0.00171875 C 0.00102 -0.0998438 -1.096636 -0.994375 -1.194293 -1.595938 \" transform=\"matrix(0,1,1,0,109.135,47.49898)\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import SVG\n",
    "SVG(filename='scatter_add.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset=jet_dataset, batch_size=3, shuffle = True)\n",
    "b_gr = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[121, 23], edge_index=[2, 605], edge_deltaR=[605, 1], label=[3], sd_mass=[3], seq_length=[3], batch=[121], ptr=[4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121,\n",
       " 605,\n",
       " tensor([[ 45,   6,   3,  ..., 111, 117, 103],\n",
       "         [  0,   0,   0,  ..., 120, 120, 120]]),\n",
       " tensor([  0,  55,  87, 121]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_gr.num_nodes, b_gr.num_edges, b_gr.edge_index, b_gr.ptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = MPNNLayer(emb_dim=23, edge_dim=1)\n",
    "out1 = layer(h=b_gr.x, edge_index=b_gr.edge_index, edge_attr=b_gr.edge_deltaR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpnn_model = MPNNModel(num_layers=4, emb_dim=64, in_dim=23, edge_dim=1, out_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = mpnn_model(b_gr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([131.3098, 100.1276, 234.1671], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit tests for Permutation Invariance and Equivariance\n",
    "\n",
    "The lectures have repeatedly indicated on certain fundamental properties for machine learning on graphs:\n",
    "- A **GNN <ins>layer**</ins> is **equivariant** to permutations of the set of nodes in the graph; i.e. as we permute the nodes, the node features produced by the GNN must permute accordingly.\n",
    "- A **GNN <ins>model**</ins> for graph-level property prediction is **invariant** to the permutations of the set of nodes in the graph; i.e. as we permute the nodes, the graph-level propery remains unchanged.\n",
    "\n",
    "(But wait...**What is a permutation?** Essentially, it is an **ordering of the nodes** in a graph. In general, there is **no canonical way** of assigning an ordering of the nodes, unlike textual or image data. However, graphs need to be stored and processed on computers in order to perform machine learning on them (which is what this course is about!). Thus, we need to ensure that our models are able to principaly handle this **lack of canonical ordering** or permutation of graph nodes. This is what the above statements are trying to say.)\n",
    "\n",
    "### Formalism\n",
    "\n",
    "Let us try to formalise these notions of permutation invariance and equivariance via matrix notation (it is easier that way).\n",
    "\n",
    "- Let $\\mathbf{H} \\in \\mathbb{R}^{n \\times d}$ be a matrix of node features for a given molecular graph, where $n$ is the number of nodes/atoms and each row $h_i$ is the $d$-dimensional feature for node $i$.\n",
    "- Let $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$ be the adjacency matrix where each entry denotes $a_{ij}$ the presence or absence of an edge between nodes $i$ and $j$.\n",
    "- Let $\\mathbf{F}(\\mathbf{H}, \\mathbf{A}): \\mathbb{R}^{n \\times d} \\times \\mathbb{R}^{n \\times n} \\rightarrow \\mathbb{R}^{n \\times d}$ be a **GNN <ins>layer**</ins> that takes as input the node features and adjacency matrix, and returns the **updated node features**.\n",
    "- Let $f(\\mathbf{H}, \\mathbf{A}): \\mathbb{R}^{n \\times d} \\times \\mathbb{R}^{n \\times n} \\rightarrow \\mathbb{R}$ be a **GNN <ins>model**</ins> that takes as input the node features and adjacency matrix, and returns the **predicted graph-level property**.\n",
    "- Let $\\mathbf{P} \\in \\mathbb{R}^{n \\times n}$ be a **[permutation matrix](https://en.wikipedia.org/wiki/Permutation_matrix)** which has exactly one 1 in every row and column, and 0s elsewhere. Left-multipying $\\mathbf{P}$ with a matrix changes the ordering of the rows of the matrix.\n",
    "\n",
    "### Permuation Equivariance\n",
    "\n",
    "The GNN <ins>layer</ins> $\\mathbf{F}$ is **permuation equivariant** as follows:\n",
    "$$ \n",
    "\\mathbf{F}(\\mathbf{PH}, \\mathbf{PAP^T}) = \\mathbf{P} \\ \\mathbf{F}(\\mathbf{H}, \\mathbf{A}).\n",
    "$$\n",
    "\n",
    "Another way to formulate the above could be: (1) Consider the updated node features $\\mathbf{H'} = \\mathbf{F}(\\mathbf{H}, \\mathbf{A})$. (2) Applying any permutation matrix $\\mathbf{P}$ to the input of the GNN layer $\\mathbf{F}$ should produce the same result as applying the same permutation on $\\mathbf{H'}$:\n",
    "$$\n",
    "\\mathbf{F}(\\mathbf{PH}, \\mathbf{PAP^T}) = \\mathbf{P} \\ \\mathbf{H'}\n",
    "$$\n",
    "\n",
    "### Permuation Invariance\n",
    "\n",
    "The GNN <ins>model</ins> $f$ for graph-level prediction is **permutation invariant** as follows:\n",
    "$$ \n",
    "f(\\mathbf{PH}, \\mathbf{PAP^T}) = f(\\mathbf{H}, \\mathbf{A}).\n",
    "$$\n",
    "\n",
    "Another way to formulate the above could be: (1) Consider the predicted molecular property $\\mathbf{\\hat y} = f(\\mathbf{H}, \\mathbf{A})$. (2) Applying any permutation matrix $\\mathbf{P}$ to the input of the GNN model $f$ should produce the same result as not applying it:\n",
    "$$ \n",
    "f(\\mathbf{PH}, \\mathbf{PAP^T}) = \\mathbf{\\hat y}.\n",
    "$$\n",
    "\n",
    "With that formalism out of the way, let us write some unit tests to confirm that our `MPNNModel` and `MPNNLayer` are indeed permutation invariant and equivariant, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permute_graph(data, perm):\n",
    "    \"\"\"Helper function for permuting PyG Data object attributes consistently.\n",
    "    \"\"\"\n",
    "    # Permute the node attribute ordering\n",
    "    data.x = data.x[perm]\n",
    "    # data.pos = data.pos[perm]\n",
    "    # data.z = data.z[perm]\n",
    "    data.batch = data.batch[perm]\n",
    "\n",
    "    # Permute the edge index\n",
    "    adj = to_dense_adj(data.edge_index)\n",
    "    adj = adj[:, perm, :]\n",
    "    adj = adj[:, :, perm]\n",
    "    data.edge_index = dense_to_sparse(adj)[0]\n",
    "\n",
    "    # Note: \n",
    "    # (1) While we originally defined the permutation matrix P as only having \n",
    "    #     entries 0 and 1, its implementation via `perm` uses indexing into \n",
    "    #     torch tensors, instead. \n",
    "    # (2) It is cumbersome to permute the edge_attr, so we set it to constant \n",
    "    #     dummy values. For any experiments beyond unit testing, all GNN models \n",
    "    #     use the original edge_attr.\n",
    "\n",
    "    return data\n",
    "\n",
    "def permutation_invariance_unit_test(module, dataloader):\n",
    "    \"\"\"Unit test for checking whether a module (GNN model) is \n",
    "    permutation invariant.\n",
    "    \"\"\"\n",
    "    it = iter(dataloader)\n",
    "    data = next(it)\n",
    "\n",
    "    # Set edge_attr to dummy values (for simplicity)\n",
    "    #data.edge_attr = torch.zeros(data.edge_attr.shape)\n",
    "\n",
    "    # Forward pass on original example\n",
    "    out_1 = module(data)\n",
    "\n",
    "    # Create random permutation\n",
    "    perm = torch.randperm(data.x.shape[0])\n",
    "    data = permute_graph(data, perm)\n",
    "\n",
    "    # Forward pass on permuted example\n",
    "    out_2 = module(data)\n",
    "\n",
    "    # Check whether output varies after applying transformations\n",
    "    return torch.allclose(out_1, out_2, atol=1e-04)\n",
    "\n",
    "\n",
    "def permutation_equivariance_unit_test(module, dataloader):\n",
    "    \"\"\"Unit test for checking whether a module (GNN layer) is \n",
    "    permutation equivariant.\n",
    "    \"\"\"\n",
    "    it = iter(dataloader)\n",
    "    data = next(it)\n",
    "\n",
    "    # Set edge_attr to dummy values (for simplicity)\n",
    "    #data.edge_attr = torch.zeros(data.edge_attr.shape)\n",
    "\n",
    "    # Forward pass on original example\n",
    "    out_1 = module(data)#module(data.x, data.edge_index, data.edge_attr)\n",
    "\n",
    "    # Create random permutation\n",
    "    perm = torch.randperm(data.x.shape[0])\n",
    "    data = permute_graph(data, perm)\n",
    "\n",
    "    # Forward pass on permuted example\n",
    "    out_2 = module(data)#module(data.x, data.edge_index, data.edge_attr)\n",
    "\n",
    "    # Check whether output varies after applying transformations\n",
    "    return torch.allclose(out_1[perm], out_2, atol=1e-04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutation_invariance_unit_test(mpnn_model, data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do you test the equivariance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[121, 23], edge_index=[2, 605], edge_deltaR=[605, 1], label=[3], sd_mass=[3], seq_length=[3], batch=[121], ptr=[4])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
